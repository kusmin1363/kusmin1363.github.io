---
layout: single
title:  "DL-5. CNN 실습"
---

# CNN 데이터 다루기
- 평소에 이미지 데이터는 csv로 저장될때 1차원으로 저장해두지만, CNN에 적용시킬 때나 이미지를 눈으로 확인할 때는 2차원으로 변형해서 사용해줘야 한다.


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
```




```python
train_df = pd.read_csv('C:\\스터디\\DACON\\DL\\fashion mnist\\train.csv')

```


```python
x_train = train_df.loc[:,'pixel1':]
y_train = train_df['label']

x_train.shape
#x_train에는 6만장의 이미지가 존재, 각 이미지는 784(28*28)개의 pixel을 가지고 있는 상황
```




    (60000, 784)




```python
labels = y_train.values
images = x_train.values  # 픽셀 값만 가져옵니다

# 첫 4개의 이미지와 레이블 가져오기
num_images_to_show = 5
images_to_show = images[:num_images_to_show]
labels_to_show = labels[:num_images_to_show]

# 각 클래스의 이름
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# 이미지 출력
plt.figure(figsize=(20, 4))
for i in range(num_images_to_show):
    img = images_to_show[i].reshape(28, 28)
    label = class_names[labels_to_show[i]]
    plt.subplot(1, 5, i+1)
    plt.imshow(img, cmap='gray')
    plt.title(label)
    plt.axis('off')

plt.tight_layout()
plt.show()
```


![Bayesian](/assets/images/2025-01-20-DL5_6_0.png)
    



```python
print(x_train.shape)
print(y_train.shape)
```

    (60000, 784)
    (60000,)
    


```python
x_train = x_train.values
y_train = y_train.values

#train_test_split을 거치면 pixel 기준으로 잘리는게 아니라, 이미지 기준으로 잘림
#따라서 6만장의 이미지를 20프로를 test data로 쓴다.
x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=24)

print(type(x_train))
#6만 * 784의 형태를 4만8천*28*28*1 로 변경
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1)

#pytorch에서 사용할 수 있게 data 순서를 4만 8천 * 1 * 28 * 28로 변경
x_train = x_train.transpose(0, 3, 1, 2)
x_valid = x_valid.transpose(0,3,1,2)

```

    <class 'numpy.ndarray'>
    


```python
x_train = torch.tensor(x_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)
x_valid = torch.tensor(x_valid, dtype=torch.float32)
y_valid = torch.tensor(y_valid, dtype=torch.long)
```

### Custom Dataset 작성



```python
class CustomDataset(Dataset):
    def __init__(self, images, labels=None, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __getitem__(self, idx):
        image = self.images[idx]

        if self.transform:
            image = self.transform(image)

        if self.labels is not None:
            label = self.labels[idx]
            return image, label
        else:
            return image
    
    def __len__(self):
        return len(self.images)
```

### Dataset으로 묶어주는 과정에서, 정규화 진행, 그후 DataLoader를 통해 mini-batch로 잘라줌


```python
transform = transforms.Compose([
    transforms.Normalize((0.5,), (0.5,))
])

train_dataset = CustomDataset(x_train, y_train, transform=transform)
valid_dataset = CustomDataset(x_valid, y_valid, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)
```

### CNN 정의
- __init__ 에서는 convolution, pooling, fully connected 에 대해서 정의하고
- forward 과정에서는 convolution->relu>pooling 2번, Flatten, 다시 Fullyconnected 연결 2번으로 진행된다.


```python
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

### 모델 학습 및 검증 함수 정의
- tqdm은 progress bar를 표시해주는 라이브러리

- 함수의 기초적인 구조
- parameter
1. model = 학습에 사용할 CNN 모델
2. criterion = 손실 함수
3. optimizer = 옵티마이저(최적화 도구)
4. train_loader = 훈련 로더(train_dataset을 mini-batch로 잘라둔 상황)
5. val_loader = train_loader와 동일한 맥락
6. num_epoch = 반복 수(기본 = 2)



```python
def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=2):
    for epoch in range(num_epochs):
        # 모델을 학습 모드로 전환(dropout, batch-정규화 등) 및 기초 변수 초기화
        model.train()
        running_loss = 0.0
        correct_train = 0
       
        #배치별로 학습 시작, tqdm 부분 진행 바 만들기 위해서 삽입. 그냥 반복문으로 생각하면 된다.
        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):
            # CPU 혹은 GPU로 데이터 전송
            images, labels = images.to(device), labels.to(device)
            # 순전파 부분(예측값 생성, 손실함수 계산)
            optimizer.zero_grad()  
            outputs = model(images)
            loss = criterion(outputs, labels)
            # 역전파 부분(미분, 손실함수에 따른 기울기 재조정)
            loss.backward()
            optimizer.step()

            #손실 정도 및 정확도 계산
            running_loss += loss.item() * images.size(0)
            # 출력된 확률들 중 제일 큰 값을 예측값으로 설정
            _, preds = torch.max(outputs, 1)
            correct_train += (preds == labels).sum().item()

        epoch_loss = running_loss / len(train_loader.dataset)
        train_accuracy = correct_train / len(train_loader.dataset)
        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')

        #모델을 평가 모드로 전환, 평가 변수 초기화
        model.eval()
        val_loss = 0.0
        correct_val = 0
        # 기울기 계산 비활성화
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                # 최종 손실함수 계산
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * images.size(0)
                # 예측 진행 및 정확도 계산
                _, preds = torch.max(outputs, 1)
                correct_val += (preds == labels).sum().item()

        val_loss /= len(val_loader.dataset)
        val_accuracy = correct_val / len(val_loader.dataset)
        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')
```

### 모델 초기화 및 학습 실행


```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=10)
```


### test data 로드 및 데이터 로더 생성


```python
test_df = pd.read_csv('C:\\스터디\\DACON\\DL\\fashion mnist\\test.csv')
x_test = test_df.iloc[:,1:].values

x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).transpose(0, 3, 1, 2)
x_test = torch.tensor(x_test, dtype=torch.float32)

test_dataset = CustomDataset(x_test, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
```

### test 데이터 예측 수행


```python
model.eval()
predictions = []

with torch.no_grad():
    for images in test_loader:
        images = images.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        predictions.extend(preds.cpu().numpy())
        
predictions[:10]
```




    [np.int64(0),
     np.int64(1),
     np.int64(2),
     np.int64(2),
     np.int64(3),
     np.int64(6),
     np.int64(8),
     np.int64(6),
     np.int64(5),
     np.int64(0)]



### 예측 결과를 파일로 저장


```python
#submission = pd.read_csv('C:\\스터디\\DACON\\DL\\fashion mnist\\sample_submission.csv')
#submission['label'] = predictions
#submission.to_csv('submission.csv', index=False)
```



