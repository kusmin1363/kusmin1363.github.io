---
layout: single
title:  "DL-5. CNN ì‹¤ìŠµ"
---

# CNN ë°ì´í„° ë‹¤ë£¨ê¸°
- í‰ì†Œì— ì´ë¯¸ì§€ ë°ì´í„°ëŠ” csvë¡œ ì €ì¥ë ë•Œ 1ì°¨ì›ìœ¼ë¡œ ì €ì¥í•´ë‘ì§€ë§Œ, CNNì— ì ìš©ì‹œí‚¬ ë•Œë‚˜ ì´ë¯¸ì§€ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•  ë•ŒëŠ” 2ì°¨ì›ìœ¼ë¡œ ë³€í˜•í•´ì„œ ì‚¬ìš©í•´ì¤˜ì•¼ í•œë‹¤.


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
```




```python
train_df = pd.read_csv('C:\\ìŠ¤í„°ë””\\DACON\\DL\\fashion mnist\\train.csv')

```


```python
x_train = train_df.loc[:,'pixel1':]
y_train = train_df['label']

x_train.shape
#x_trainì—ëŠ” 6ë§Œì¥ì˜ ì´ë¯¸ì§€ê°€ ì¡´ì¬, ê° ì´ë¯¸ì§€ëŠ” 784(28*28)ê°œì˜ pixelì„ ê°€ì§€ê³  ìˆëŠ” ìƒí™©
```




    (60000, 784)




```python
labels = y_train.values
images = x_train.values  # í”½ì…€ ê°’ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤

# ì²« 4ê°œì˜ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸” ê°€ì ¸ì˜¤ê¸°
num_images_to_show = 5
images_to_show = images[:num_images_to_show]
labels_to_show = labels[:num_images_to_show]

# ê° í´ë˜ìŠ¤ì˜ ì´ë¦„
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# ì´ë¯¸ì§€ ì¶œë ¥
plt.figure(figsize=(20, 4))
for i in range(num_images_to_show):
    img = images_to_show[i].reshape(28, 28)
    label = class_names[labels_to_show[i]]
    plt.subplot(1, 5, i+1)
    plt.imshow(img, cmap='gray')
    plt.title(label)
    plt.axis('off')

plt.tight_layout()
plt.show()
```


![Bayesian](/assets/images/2025-01-20-DL5_6_0.png)
    



```python
print(x_train.shape)
print(y_train.shape)
```

    (60000, 784)
    (60000,)
    


```python
x_train = x_train.values
y_train = y_train.values

#train_test_splitì„ ê±°ì¹˜ë©´ pixel ê¸°ì¤€ìœ¼ë¡œ ì˜ë¦¬ëŠ”ê²Œ ì•„ë‹ˆë¼, ì´ë¯¸ì§€ ê¸°ì¤€ìœ¼ë¡œ ì˜ë¦¼
#ë”°ë¼ì„œ 6ë§Œì¥ì˜ ì´ë¯¸ì§€ë¥¼ 20í”„ë¡œë¥¼ test dataë¡œ ì“´ë‹¤.
x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=24)

print(type(x_train))
#6ë§Œ * 784ì˜ í˜•íƒœë¥¼ 4ë§Œ8ì²œ*28*28*1 ë¡œ ë³€ê²½
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1)

#pytorchì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ data ìˆœì„œë¥¼ 4ë§Œ 8ì²œ * 1 * 28 * 28ë¡œ ë³€ê²½
x_train = x_train.transpose(0, 3, 1, 2)
x_valid = x_valid.transpose(0,3,1,2)

```

    <class 'numpy.ndarray'>
    


```python
x_train = torch.tensor(x_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)
x_valid = torch.tensor(x_valid, dtype=torch.float32)
y_valid = torch.tensor(y_valid, dtype=torch.long)
```

### Custom Dataset ì‘ì„±
ì´ ì½”ë“œì—ì„œ ì‘ì„±í•˜ì‹  CustomDataset í´ë˜ìŠ¤ëŠ” **PyTorchì˜ Dataset**ì„ ìƒì†ë°›ì•„ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ ë§Œë“œëŠ” ë°©ë²•ì´ì—ìš”. ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê³µê¸‰í•˜ê¸° ìœ„í•´ DataLoaderì™€ í•¨ê»˜ ì‚¬ìš©ë©ë‹ˆë‹¤. ğŸ˜„


```python
class CustomDataset(Dataset):
    def __init__(self, images, labels=None, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __getitem__(self, idx):
        image = self.images[idx]

        if self.transform:
            image = self.transform(image)

        if self.labels is not None:
            label = self.labels[idx]
            return image, label
        else:
            return image
    
    def __len__(self):
        return len(self.images)
```

### Datasetìœ¼ë¡œ ë¬¶ì–´ì£¼ëŠ” ê³¼ì •ì—ì„œ, ì •ê·œí™” ì§„í–‰, ê·¸í›„ DataLoaderë¥¼ í†µí•´ mini-batchë¡œ ì˜ë¼ì¤Œ


```python
transform = transforms.Compose([
    transforms.Normalize((0.5,), (0.5,))
])

train_dataset = CustomDataset(x_train, y_train, transform=transform)
valid_dataset = CustomDataset(x_valid, y_valid, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)
```

### CNN ì •ì˜
- __init__ ì—ì„œëŠ” convolution, pooling, fully connected ì— ëŒ€í•´ì„œ ì •ì˜í•˜ê³ 
- forward ê³¼ì •ì—ì„œëŠ” convolution->relu>pooling 2ë²ˆ, Flatten, ë‹¤ì‹œ Fullyconnected ì—°ê²° 2ë²ˆìœ¼ë¡œ ì§„í–‰ëœë‹¤.


```python
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

### ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜ ì •ì˜
- tqdmì€ progress barë¥¼ í‘œì‹œí•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

- í•¨ìˆ˜ì˜ ê¸°ì´ˆì ì¸ êµ¬ì¡°
- parameter
    - 1. model = í•™ìŠµì— ì‚¬ìš©í•  CNN ëª¨ë¸
    - 2. criterion = ì†ì‹¤ í•¨ìˆ˜
    - 3. optimizer = ì˜µí‹°ë§ˆì´ì €(ìµœì í™” ë„êµ¬)
    - 4. train_loader = í›ˆë ¨ ë¡œë”(train_datasetì„ mini-batchë¡œ ì˜ë¼ë‘” ìƒí™©)
    - 5. val_loader = train_loaderì™€ ë™ì¼í•œ ë§¥ë½
    - 6. num_epoch = ë°˜ë³µ ìˆ˜(ê¸°ë³¸ = 2)



```python
def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=2):
    for epoch in range(num_epochs):
        # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜(dropout, batch-ì •ê·œí™” ë“±) ë° ê¸°ì´ˆ ë³€ìˆ˜ ì´ˆê¸°í™”
        model.train()
        running_loss = 0.0
        correct_train = 0
       
        #ë°°ì¹˜ë³„ë¡œ í•™ìŠµ ì‹œì‘, tqdm ë¶€ë¶„ ì§„í–‰ ë°” ë§Œë“¤ê¸° ìœ„í•´ì„œ ì‚½ì…. ê·¸ëƒ¥ ë°˜ë³µë¬¸ìœ¼ë¡œ ìƒê°í•˜ë©´ ëœë‹¤.
        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):
            # CPU í˜¹ì€ GPUë¡œ ë°ì´í„° ì „ì†¡
            images, labels = images.to(device), labels.to(device)
            # ìˆœì „íŒŒ ë¶€ë¶„(ì˜ˆì¸¡ê°’ ìƒì„±, ì†ì‹¤í•¨ìˆ˜ ê³„ì‚°)
            optimizer.zero_grad()  
            outputs = model(images)
            loss = criterion(outputs, labels)
            # ì—­ì „íŒŒ ë¶€ë¶„(ë¯¸ë¶„, ì†ì‹¤í•¨ìˆ˜ì— ë”°ë¥¸ ê¸°ìš¸ê¸° ì¬ì¡°ì •)
            loss.backward()
            optimizer.step()

            #ì†ì‹¤ ì •ë„ ë° ì •í™•ë„ ê³„ì‚°
            running_loss += loss.item() * images.size(0)
            # ì¶œë ¥ëœ í™•ë¥ ë“¤ ì¤‘ ì œì¼ í° ê°’ì„ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì„¤ì •
            _, preds = torch.max(outputs, 1)
            correct_train += (preds == labels).sum().item()

        epoch_loss = running_loss / len(train_loader.dataset)
        train_accuracy = correct_train / len(train_loader.dataset)
        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')

        #ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜, í‰ê°€ ë³€ìˆ˜ ì´ˆê¸°í™”
        model.eval()
        val_loss = 0.0
        correct_val = 0
        # ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                # ìµœì¢… ì†ì‹¤í•¨ìˆ˜ ê³„ì‚°
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * images.size(0)
                # ì˜ˆì¸¡ ì§„í–‰ ë° ì •í™•ë„ ê³„ì‚°
                _, preds = torch.max(outputs, 1)
                correct_val += (preds == labels).sum().item()

        val_loss /= len(val_loader.dataset)
        val_accuracy = correct_val / len(val_loader.dataset)
        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')
```

### ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ ì‹¤í–‰


```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=10)
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    Cell In[1], line 1
    ----> 1 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
          3 model = SimpleCNN().to(device)
          4 criterion = nn.CrossEntropyLoss()
    

    NameError: name 'torch' is not defined


### test data ë¡œë“œ ë° ë°ì´í„° ë¡œë” ìƒì„±


```python
test_df = pd.read_csv('C:\\ìŠ¤í„°ë””\\DACON\\DL\\fashion mnist\\test.csv')
x_test = test_df.iloc[:,1:].values

x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).transpose(0, 3, 1, 2)
x_test = torch.tensor(x_test, dtype=torch.float32)

test_dataset = CustomDataset(x_test, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
```

### test ë°ì´í„° ì˜ˆì¸¡ ìˆ˜í–‰


```python
model.eval()
predictions = []

with torch.no_grad():
    for images in test_loader:
        images = images.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        predictions.extend(preds.cpu().numpy())
        
predictions[:10]
```




    [np.int64(0),
     np.int64(1),
     np.int64(2),
     np.int64(2),
     np.int64(3),
     np.int64(6),
     np.int64(8),
     np.int64(6),
     np.int64(5),
     np.int64(0)]



### ì˜ˆì¸¡ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥


```python
#submission = pd.read_csv('C:\\ìŠ¤í„°ë””\\DACON\\DL\\fashion mnist\\sample_submission.csv')
#submission['label'] = predictions
#submission.to_csv('submission.csv', index=False)
```


```python

```


