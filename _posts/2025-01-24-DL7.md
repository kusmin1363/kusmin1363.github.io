---
layout: single
title:  "DL-7. Pre-trained Model"
---


# Pre-trained Model 이란?
- 다른 사람들이 이미 학습해 놓은 Model을 사용
- 용도에 맞는 모델을 사용할 경우 효율적으로 결과를 얻을 수 있음.

## 1. 과거 CNN 모델
    - 1. LeNet-5 : 간단한 구조, 빠른 연산 속도를 지님. 손글씨 인식에 사용됨.
    - 2. AlexNet : ReLU와 Dropout을 도입, GPU 활용을 통한 병렬 연산 진행. -> ImageNet 대회에서 우승했던 모델

## 2. 더 발전된 경우
    - 1. VCGNet : Deep Network, 3*3 filter 사용, 이미지 분류용으로 사용됨.
    - 2. GoogLeNet(Interception V1) : Inception 모듈(다양한 필터를 번갈아 가며 사용)을 도입해 효율성 증가, 실시간 이미지 인식에 적합
    - 3. ResNet : Residual Connection을 도입해 50층이 넘는 매우 깊은 네트워크에서도 학습이 가능함.

## 3. 효율성과 경량성을 추가한 모델
    - 1. MobileNet : Depthwise Separable Convolutions을 도입, 효율성 극대화, 모바일 및 임베디드 시스템을 위한 경량 모델
    - 2. EfficientNet : Compound Scaling 도입(모델의 크기, 깊이, 해상도를 균형있게 조절), 효율성 미쳤따.

## 4. 트랜스포머 기반 모델
    - 1. ViT : 이미지 분류를 위해 트랜스포머 아키텍쳐를 접목시켜 CNN 없이 좋은 성능 발휘
    - 2. Swin Transformer : 이중 윈도우 기반의 Self-attention으로 효율성을 높임

# LeNet-5 직접 만들기
- LeNet-5는 숫자 손글씨를 인식하기 위해 사용되었던 모델이다. 
- Conv1, Pool, Conv2, Pool, Conv3 라는 5가지 CNN을 가지고 있으며, 이후 2번의 FC Layer가 결합되어 있는 형태이다.
- 중요한 점은 CNN과 FC Layer를 구분했다는 점인데, CNN이 그려진 숫자에서 여러 가지 패턴(기울기, 곡선 등)을 학습해서 전달해주면, FC Layer가 이를 보고 이 숫자가 어떤 숫자인지 판독한다는 점이다.
- 쉽게 말해, CNN이 **이미지 분석**을, FC Layer가 **숫자 결정** 역할을 한다는 것이다.


```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
```

## 1. Input은 32 * 32 * 1짜리 흑백 이미지이다.


```python
x = torch.rand(1,1,32,32) #batch_size, depth, width, height 순
```

## 2. CNN 지나서 28 * 28 * 6 으로 변한다. 활성화 함수는 tanh


```python
conv1 = nn.Conv2d(1, 6, kernel_size=5)

x = torch.tanh(conv1(x))
print(x.shape)
```

    torch.Size([1, 6, 28, 28])
    

## 3. Average Pooling 지나서 14 * 14 * 6 으로 변한다.


```python
pool = nn.AvgPool2d(kernel_size=2, stride=2)
x = pool(x)
```

## 4. 다시 Convolution을 지나서 10 * 10 * 16으로 변한다.


```python
conv2 = nn.Conv2d(6, 16, kernel_size=5)

x = torch.tanh(conv2(x))
print(x.shape)
```

    torch.Size([1, 16, 10, 10])
    

## 5. Average Pooling 지나서 5 * 5 * 16 으로 변한다.


```python
pool = nn.AvgPool2d(kernel_size=2, stride=2)
x = pool(x)
```

## 6. 마지막 COnvolution을 지나면 1* 1* 120으로 된다


```python
conv3 = nn.Conv2d(16,120, kernel_size=5)
x = torch.tanh(conv3(x))
x.shape
```




    torch.Size([1, 120, 1, 1])



## 7. x를 평탄화를 통해 vector로 바꿔준다.


```python
flat_x = x.view(-1, 120)
flat_x.shape
```




    torch.Size([1, 120])




```python
fc_1 = nn.Linear(120,84)
x = torch.tanh(fc_1(flat_x))
## 마지막 출력 Layer에서는 활성화 함수 적용 안함.
fc_2 = nn.Linear(84,10)
x = fc_2(x)
```

## 한번에 nn.Module을 상속해 클래스로 만들기


```python
class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5,self).__init__()
        self.conv1 = nn.Conv2d(1,6,kernel_size=5)
        self.pool = nn.AvgPool2d(kernel_size=2, stride = 2)
        self.conv2 = nn.Conv2d(6,16,kernel_size=5)
        self.conv3 = nn.Conv2d(16,120, kernel_size=5)
        self.fc1 = nn.Linear(120,84)
        self.fc2 = nn.Linear(84,10)

    def forward(self,x):
        x = torch.tanh(self.conv1(x))
        x = self.pool(x)
        x = torch.tanh(self.conv2(x))
        x = self.pool(x)
        x = torch.tanh(self.conv3(x))
        x = x.view(-1,120)
        x = torch.tanh(self.fc1(x))
        x = self.fc2(x)
        return x
    
model = LeNet5()
model

```




    LeNet5(
      (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
      (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))
      (fc1): Linear(in_features=120, out_features=84, bias=True)
      (fc2): Linear(in_features=84, out_features=10, bias=True)
    )


# AlexNet 만들기
- AlexNet은 거대 데이터셋인 ImageNet을 활용한 대회에서 우승한 모델이다.
- 특징으로는 activation function으로 ReLU를 썼다는 점, 데이터 증강과 dropout으로 과적합을 방지했다는 점이다. 추가로 당시 기술력의 발전으로 GPU를 데이터 처리에 사용할 수 있게 되었다.
- 당시에 주로 사용하던 tanh, sigmoid보다 훨씬 효율 좋은 ReLU는 gradient vanishing 문제 완화에 크게 기여했고, 과적합을 방지하기 위해 다양한 variation을 준 이미지를 추가해줬다.

AlexNet은 5개의 Convolution Layer, 3개의 FC layer로 구성되어 있다. 입력은 227 * 227 * 3 이었다.  
Conv1 -> Pool -> Conv2 -> Pool -> Conv3 -> Conv4 -> Conv5 -> Pool -> FC 1 -> Fc 2 


```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
```


```python
x = torch.rand(1,3,227,227)
```

## Conv1 에서는 11 * 11 * 96, stride = 4, padding = 1 옵션을 사용했다


```python
conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding = 1)
x_conv1 = F.relu(conv1(x))
x_conv1.shape
```




    torch.Size([1, 96, 55, 55])



## MaxPooling을 사용했다


```python
pool1 = nn.MaxPool2d(kernel_size=3, stride= 2)
x_pool1 = pool1(x_conv1)
x_pool1.shape
```




    torch.Size([1, 96, 27, 27])




```python
conv2 = nn.Conv2d(96, 256, kernel_size=5, stride=1, padding = 2)
x_conv2 = F.relu(conv2(x_pool1))
print(x_conv2.shape)
x_pool2 = pool1(x_conv2)
print(x_pool2.shape)
```

    torch.Size([1, 256, 27, 27])
    torch.Size([1, 256, 13, 13])
    


```python
conv3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding = 1)
x_conv3 = F.relu(conv3(x_pool2))
print(x_conv3.shape)
conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding = 1)
x_conv4 = F.relu(conv4(x_conv3))
print(x_conv4.shape)
conv5 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding = 1)
x_conv5 = F.relu(conv5(x_conv4))
print(x_conv5.shape)
```

    torch.Size([1, 384, 13, 13])
    torch.Size([1, 384, 13, 13])
    torch.Size([1, 256, 13, 13])
    


```python
x_pool3 = pool1(x_conv5)
x_pool3.shape
```




    torch.Size([1, 256, 6, 6])



## 6 * 6 * 256에서 분류를 시작한다.


```python
flat_x = x_pool3.view(x_pool3.size(0), -1)
print(flat_x.shape)

dropout = nn.Dropout(p=0.5)
x_drop1 = dropout(flat_x)

fc1 = nn.Linear(256*6*6, 4096)
x_fc1 = F.relu(fc1(x_drop1))
print(x_fc1.shape)

x_drop2 = dropout(x_fc1)

fc2 = nn.Linear(4096,4096)
x_fc2 = F.relu(fc2(x_drop2))
print(x_fc2.shape)

fc3 = nn.Linear(4096,1000)
x_output = fc3(x_fc2)
print(x_output.shape)
```

    torch.Size([1, 9216])
    torch.Size([1, 4096])
    torch.Size([1, 4096])
    torch.Size([1, 1000])
    

# 한번에 모듈로 작성해보기


```python
class AlexNet(nn.Module):
    def __init__(self):
        super(AlexNet, self).__init__()

        # 특징 추출 (feature extraction) 부분을 위한 레이어 정의
        self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1)
        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2)
        self.conv3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1)
        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1)

        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)

        # 분류기(Classifier) 부분을 위한 레이어 정의
        self.fc1 = nn.Linear(256 * 6 * 6, 4096)
        self.fc2 = nn.Linear(4096, 4096)
        self.fc3 = nn.Linear(4096, 1000)

        self.dropout = nn.Dropout()

    def forward(self, x):
        # 특징 추출 (feature extraction) 부분
        x = F.relu(self.conv1(x)) # conv + relu
        x = self.pool(x) # MaxPooling
        x = F.relu(self.conv2(x)) # conv + relu
        x = self.pool(x)  # MaxPooling
        x = F.relu(self.conv3(x)) # conv + relu
        x = F.relu(self.conv4(x)) # conv + relu
        x = F.relu(self.conv5(x)) # conv + relu
        x = self.pool(x)  # MaxPooling

        # 완전 연결 계층을 위한 텐서 평탄화
        x = x.view(x.size(0), -1)

        # 분류기(Classifier) 부분
        x = self.dropout(x) # Dropout
        x = F.relu(self.fc1(x)) # fc + relu
        x = self.dropout(x) # Dropout
        x = F.relu(self.fc2(x)) # fc + relu
        x = self.fc3(x) # fc

        return x
```


```python
from torchsummary import summary

model = AlexNet()
summary(model, (3, 227, 227))
```

    ----------------------------------------------------------------
            Layer (type)               Output Shape         Param #
    ================================================================
                Conv2d-1           [-1, 96, 55, 55]          34,944
             MaxPool2d-2           [-1, 96, 27, 27]               0
                Conv2d-3          [-1, 256, 27, 27]         614,656
             MaxPool2d-4          [-1, 256, 13, 13]               0
                Conv2d-5          [-1, 384, 13, 13]         885,120
                Conv2d-6          [-1, 384, 13, 13]       1,327,488
                Conv2d-7          [-1, 256, 13, 13]         884,992
             MaxPool2d-8            [-1, 256, 6, 6]               0
               Dropout-9                 [-1, 9216]               0
               Linear-10                 [-1, 4096]      37,752,832
              Dropout-11                 [-1, 4096]               0
               Linear-12                 [-1, 4096]      16,781,312
               Linear-13                 [-1, 1000]       4,097,000
    ================================================================
    Total params: 62,378,344
    Trainable params: 62,378,344
    Non-trainable params: 0
    ----------------------------------------------------------------
    Input size (MB): 0.59
    Forward/backward pass size (MB): 6.07
    Params size (MB): 237.95
    Estimated Total Size (MB): 244.61
    ----------------------------------------------------------------
    
